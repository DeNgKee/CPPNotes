# 17. C++11并发编程

 ![Process-thread relationship](https://computing.llnl.gov/tutorials/pthreads/images/thread.gif) 

*C++11*的*std::thread*是经过良好设计并且跨平台的线程表示方式，在类*Unix*平台上是对*pthread*进行的面向对象封装（增加了易用性，也损失了一些功能，所以*pthread*是*C++11*并发编程库的超集），比如*std::thread*的构造函数中调用的就是*pthread_create*来创建线程。如果在代码中使用了*std::thread*，还需要另外链接*libpthread.so*；而在*Windows*上有自己另外的封装。

我们首先来介绍一下*pthread*。

## 17.1 *pthread*

pthread是POSIX的线程标准，定义了创建和操纵线程的一套API。实现POSIX 线程标准的库常被称作**Pthreads**，一般用于Unix-like POSIX 系统，如Linux、Solaris。Linux的pthread实现是*Native POSIX Thread Library* (*NPTL*)。在Linux2.6之前进程是内核调度的实体，在内核中并不能真正支持线程。但是它的确可以通过 `clone()` 系统调用将进程作为可调度的实体。这个调用创建了调用进程（calling process）的一个拷贝，这个拷贝与调用进程共享相同的地址空间。LinuxThreads 项目使用这个调用来完全在用户空间模拟对线程的支持。不幸的是，这种方法有一些缺点，尤其是在信号处理、调度和进程间同步原语方面都存在问题。另外，这个线程模型也不符合 POSIX 的要求。要改进 LinuxThreads，非常明显我们需要内核的支持，并且需要重写线程库。有两个相互竞争的项目开始来满足这些要求。一个包括 IBM 的开发人员的团队开展了 NGPT（Next-Generation POSIX Threads）项目。同时，Red Hat 的一些开发人员开展了 NPTL 项目。NGPT 在 2003 年中期被放弃了，把这个领域完全留给了 NPTL。 

> reference:
>
> https://www.ibm.com/developerworks/cn/linux/l-threading.html
>
> https://computing.llnl.gov/tutorials/pthreads/

pthread定义了一套C语言的类型、函数与常量，它以`pthread.h`头文件和一个线程库实现。

pthread API中大致共有100个函数调用，全都以"pthread_"开头，并可以分为四类：

- 线程管理，例如创建线程，等待(join)线程，查询线程状态等。
- 互斥锁（Mutex）：创建、摧毁、锁定、解锁、设置属性等操作
- 条件变量（Condition Variable）：创建、摧毁、等待、通知、设置与查询属性等操作
- 使用了互斥锁的线程间的同步管理

POSIX的Semaphore API可以和pthread协同工作，但这并不是pthread的标准。因而这部分API是以"sem\_"打头，而非"pthread_"。下面是一个简单用例：

``` cpp
#include <stdio.h>
#include <stdlib.h>
#include <time.h>
#include <pthread.h>

static void wait(void)
{
    time_t start_time = time(NULL);
    while (time(NULL) == start_time){
        /* do nothing except chew CPU slices for up to one second */
    }
}

static void *thread_func(void *vptr_args)
{
    int i;
    for (i = 0; i < 20; i++){
        fputs("  b\n", stderr);
        wait();
    }
    return NULL;
}

int main(void)
{
    int i;
    pthread_t thread;

    if (pthread_create(&thread, NULL, thread_func, NULL) != 0){
        return EXIT_FAILURE;
    }
    for (i = 0; i < 20; i++){
        puts("a");
        wait();
    }
    if (pthread_join(thread, NULL) != 0){
        return EXIT_FAILURE;
    }
    return EXIT_SUCCESS;
}
```

## 17.2 *std::thread*

*std::thread*封装了*pthread*的线程管理接口，相对于*pthread*最方便的地方在于不需要将参数打包在一个*void\**中进行参数传入，*std::thread*使用模板函数对多参数进行了打包从而让我们能将参数一个一个的传入。

> reference:https://www.zhihu.com/question/30553807

常用的成员函数有：

```cpp
thread() noexcept;//默认构造函数并不代表有线程开始执行，non-joinable
template <class Fn, class... Args>
explicit thread (Fn&& fn, Args&&... args);//若参数为引用类型我们可以用std::ref进行转换
thread (const thread&) = delete;//禁止拷贝构造函数但是允许移动语义
thread (thread&& x) noexcept;
void detach();//不能被其他线程回收或杀死的，资源在终止时由系统自动释放
void join();//和detach一样执行之后都变成non-joinable，但是join为阻塞的
native_handle_type native_handle();//This member function is only present in class thread if the library implementation supports it. 例如在linux就获得pthread_t
id get_id() const noexcept;
~thread();//如果析构时thread仍然是joinable的，则会调用std::terminate()抛出异常
```

前面说*std::thread*损失了一些功能，比如说设置线程的*cpu affinity*，这时候我们可以通过`native_handle()`获得*pthread*的句柄，然后通过*pthread*的接口来设置*cpu affinity*：

```cpp
#include <thread>
#include <chrono>
#include <unistd.h>
#include <pthread.h>
using namespace std;

void Foo()
{
    auto start = std::chrono::high_resolution_clock::now();
    auto end = std::chrono::high_resolution_clock::now();
    float ms = 0.0;
    while(1){
        int sum = 0;
        start = std::chrono::high_resolution_clock::now();
        for(int i=0;i<100000;++i){
            sum += 1;
        }
        end = std::chrono::high_resolution_clock::now();
        ms = std::chrono::duration<float, std::milli>(end - start).count();
        usleep(ms * 1000);//让cpu占用率为50%
    }
}
int main()
{
    cpu_set_t cpuset;
    CPU_ZERO(&cpuset);
    CPU_SET(2, &cpuset);//设置cpu2的亲和性
    thread t1(Foo);
    pthread_t nativeThread = t1.native_handle();
    pthread_setaffinity_np(nativeThread, sizeof(cpu_set_t), &cpuset);
    t1.join();
    return 0;
}
```

## 17.3 *std::mutex*

*std::mutex*互斥锁用来对临界区域加锁（可以理解为值为0或1的semaphore），和自旋锁(*spin lock*)的区别在于mutex是sleep-waiting。就是说当没有获得mutex时，会有上下文切换，将当前线程阻塞加到等待队列中，直到持有mutex的线程释放mutex并唤醒当前线程，这时CPU是空闲的，可以调度别的任务处理；而自旋锁是busy-waiting的，就是说当没有可用的锁时，就一直忙等待并不停的进行锁请求，直到得到这个锁为止，这个过程中CPU始终处于繁忙状态不能处理别的任务。

### 17.3.1 pthread_mutex_t加锁原理

linux平台的std::mutex是pthread_mutex_t封装，我们可以查看pthread_mutex_t源码来看std::mutex的实现，其结构体内容如下：

```cpp
typedef union
{
    struct __pthread_mutex_s
    {
        int __lock;//mutex状态，0表示未占用，1表示占用
    	unsigned int __count;//用于可重入锁，记录owner线程持有锁的次数
    	int __owner;//owner线程ID
   		unsigned int __nusers;
    	/* KIND must stay at this position in the structure to maintain
        binary compatibility.  */
    	int __kind;//记录mutex的类型
    	int __spins;
    	__pthread_list_t __list;
  } __data;
  ......
} pthread_mutex_t;
```

其中` __kind  `有四种模式，分别为：

```cpp
PTHREAD_MUTEX_TIMED_NP//这是缺省值，也就是普通锁。
PTHREAD_MUTEX_RECURSIVE_NP//可重入锁，允许同一个线程对同一个锁成功获得多次，并通过多次unlock解锁。
PTHREAD_MUTEX_ERRORCHECK_NP//检错锁，如果同一个线程重复请求同一个锁，则返回EDEADLK，否则与PTHREAD_MUTEX_TIMED_NP类型相同。
PTHREAD_MUTEX_ADAPTIVE_NP//自适应锁，自旋锁与普通锁的混合。
```

而C++11其实只实现了普通锁std::mutex和重入锁std::recursive_mutex，C++17多了shared_mutex（读写锁），自旋锁需要我们自己实现，我们会在17.5章节中使用std::atomic来实现。

pthread中使用 pthread_mutex_lock接口来对4种锁进行加锁，我们可以看一下其中的操作：

```cpp
if (__builtin_expect (type, PTHREAD_MUTEX_TIMED_NP) == PTHREAD_MUTEX_TIMED_NP)
{
    simple:
    /* Normal mutex.普通锁 */
    LLL_MUTEX_LOCK (mutex);//调用LLL_MUTEX_LOCK宏获得锁
    assert (mutex->__data.__owner == 0);
} else if (__builtin_expect (type == PTHREAD_MUTEX_RECURSIVE_NP, 1)) {
      /* Recursive mutex.当发现owner就是自身，只是简单的自增__count成员即返回。否则，调用LLL_MUTEX_LOCK宏获得锁，若能成功获得，设置__count = 1，否则挂起。*/

	/* Check whether we already hold the mutex.  */
	if (mutex->__data.__owner == id)
	{
		/* Just bump the counter.  */
		if (__builtin_expect (mutex->__data.__count + 1 == 0, 0))
		/* Overflow of the counter.  */
			return EAGAIN;
		++mutex->__data.__count;
		return 0;
	}

    /* We have to get the mutex.  */
    LLL_MUTEX_LOCK (mutex);

    assert (mutex->__data.__owner == 0);
    mutex->__data.__count = 1;
} else if (__builtin_expect (type == PTHREAD_MUTEX_ADAPTIVE_NP, 1)) {
    /*spin lock，这种锁分两个阶段。第一阶段是自旋锁（spin lock），忙等待一段时间后，若还不能获得锁，则转变成普通锁。所谓“忙等待”，在x86处理器下是重复执行nop指令，nop是x86的小延迟函数：*/
	if (! __is_smp)
   		goto simple;

	if (LLL_MUTEX_TRYLOCK (mutex) != 0)
    {
        int cnt = 0;
        int max_cnt = MIN (MAX_ADAPTIVE_COUNT, mutex->__data.__spins * 2 + 10);
        do
        {
            if (cnt++ >= max_cnt)
        	{	
            	LLL_MUTEX_LOCK (mutex);
            	break;
        	}

#ifdef BUSY_WAIT_NOP
        	BUSY_WAIT_NOP;//#define BUSY_WAIT_NOP   asm ("rep; nop")
#endif
		}
    	while (LLL_MUTEX_TRYLOCK (mutex) != 0);

    	mutex->__data.__spins += (cnt - mutex->__data.__spins) / 8;
    }
    assert (mutex->__data.__owner == 0);
} else {
    assert (type == PTHREAD_MUTEX_ERRORCHECK_NP);
      /* Check whether we already hold the mutex.它会侦测一个线程重复申请锁的情况，如遇到，报EDEADLK，从而避免这种最简单的死锁情形。若无死锁情形，goto simple语句会跳到普通锁的处理流程。*/
    if (__builtin_expect (mutex->__data.__owner == id, 0))
        return EDEADLK;
    goto simple;
}
```

通过上面的代码我们可以看到获取锁的核心代码是*LLL_MUTEX_LOCK*宏，该宏的实现为：

```cpp
#define LLL_MUTEX_LOCK(mutex) \
	lll_lock ((mutex)->__data.__lock, PTHREAD_MUTEX_PSHARED (mutex))//PTHREAD_MUTEX_PSHARED宏表示该锁是进程锁还是线程锁，0表示线程锁，128表示进程锁
```

通过该宏我们可以看到将mutex的\_\_data.\_\_lock字段传入了lll\_lock函数中进行lock状态的修改，lll_lock的实现代码如下：

```c
__lll_lock (int *futex, int private)
{
	int val = atomic_compare_and_exchange_val_24_acq (futex, 1, 0);
	if (__glibc_unlikely (val != 0))
	{
		if (__builtin_constant_p (private) && private == LLL_PRIVATE)
			__lll_lock_wait_private (futex);
		else
			__lll_lock_wait (futex, private);
    }
}
```

*atomic_compare_and_exchange_val_24_acq*和我们std::atomic的成员函数compare_exchange_strong的功能一样，若futex的值等于0，表示锁可以被当前线程占用，则将其置为1，val返回0；若futex值不等0，表示锁被其他线程占用，则futex不变，val返回1。后面判断若`val != 0`则调用`__lll_lock_wait`进行等待：

```c
/*
futex有三种状态
0 锁空闲
1 没有waiter，解锁之后无需调用futex_wake
2 有waiter，那么解锁之后需要调用futex_wake
*/
void __lll_lock_wait (int *futex, int private)
{
	/* 非第一个线程会阻塞在这里 */
	if (*futex == 2)  
		lll_futex_wait (futex, 2, private); /* Wait if *futex == 2.  */
 
	/* 第一个线程会阻塞在这里，atomic_exchange_acq返回当前futex值并将其赋为2*/
	while (atomic_exchange_acq (futex, 2) != 0)
		lll_futex_wait (futex, 2, private); /* Wait if *futex == 2.  */
}
```

最终在`__lll_lock_wait`中调用` lll_futex_wait  `，` lll_futex_wait  `是个宏，展开后为：

```c
#define lll_futex_wait(futex, val) \
({ \
...
__asm __volatile (LLL_EBX_LOAD \
	LLL_ENTER_KERNEL \
	LLL_EBX_LOAD \
	: "=a" (__status) \
	: "0" (SYS_futex), LLL_EBX_REG (futex), "S" (0), \
	"c" (FUTEX_WAIT), "d" (_val), \
	"i" (offsetof (tcbhead_t, sysinfo)) \
	: "memory"); \
... \
})
```

可以看到当发生竞争的时候，会调用SYS_futex系统调用， 调用futex系统调用的futex_wait操作进行排队。因为用户空间并不知道内核的futex队列中是否还有其它锁竞争的任务在等待，所以系统调用阻塞唤醒回到用户空间，对futex尝试上锁，必须以锁竞争状态来上锁，以使自己解锁时，会调用futex_wake。 futex的优点在于只有当处于竞争状态的时候才会调用系统调用陷入内核。

### 17.3.2 常用函数

```cpp
void lock();//如果当前mutx被其他线程锁定，则该接口会阻塞当前线程直至解锁；如果被同一个线程锁定，则会造成死锁
native_handle_type native_handle();//和native_handle类似，在linux下会获得pthread_mutex_t
bool try_lock();//若锁被其他线程占用会返回false，若被自己占用会造成死锁
void unlock();//If the mutex is not currently locked by the calling thread, it causes undefined behavior.
```

### 17.3.3 相关类

 #### 17.3.3.1 lock_guard

这个接口我们在前文介绍过，通过RAII实现，生成对象时就加锁，在析构时进行解锁，所以锁的生命周期和对象的生命周期一样，使用方式像下面这样：

```cpp
std::mutex mtx;
{
    std::lock_guard<std::mutex> lck (mtx);
}//此时生命周期为大括号
```

对象不能复制只能移动。

#### 17.3.3.2 unique_lock

unique_lock和lock_guard类似，默认情况下锁的生命周期也是和对象一样，但是我们可以通过传入不同的参数进行灵活修改：

| value       | description                                                  |
| ----------- | ------------------------------------------------------------ |
| *(no tag)*  | Lock on construction by calling member lock.                 |
| try_to_lock | Attempt to lock on construction by calling member try_lock.  |
| defer_lock  | Do not lock on construction (and assume it is not already locked by thread). |
| adopt_lock  | Adopt current lock (assume it is already locked by thread).  |

所以unique_lock有如下构造函数：

```cpp
unique_lock() noexcept;
explicit unique_lock (mutex_type& m);
unique_lock (mutex_type& m, try_to_lock_t tag);
unique_lock (mutex_type& m, defer_lock_t tag) noexcept;
unique_lock (mutex_type& m, adopt_lock_t tag);
template <class Rep, class Period>
unique_lock (mutex_type& m, const chrono::duration<Rep,Period>& rel_time);
template <class Clock, class Duration>
unique_lock (mutex_type& m, const chrono::time_point<Clock,Duration>& abs_time);
unique_lock (const unique_lock&) = delete;
unique_lock (unique_lock&& x);
```

可以看到我们还能设定加锁时间，另外我们也可以不在构造函数时设定这些属性，可以通过成员函数重新设定：

```cpp
explicit operator bool() const noexcept;//true is the object owns a lock on the managed mutex object.
bool owns_lock() const noexcept;//true is the object owns a lock on the managed mutex object.
mutex_type* release() noexcept;//Returns a pointer to the managed mutex object, releasing ownership over it.
void lock();//Calling lock on a mutex object that has already been locked by other threads causes the current thread to block (wait) until it can own a lock to it.
bool try_lock();
template <class Rep, class Period>
bool try_lock_for (const chrono::duration<Rep,Period>& rel_time);//加锁一段时间，加锁成功返回true
template <class Clock, class Duration>
bool try_lock_until (const chrono::time_point<Clock,Duration>& abs_time);//一段时间后加锁，加锁成功返回true	
```

### 17.3.4 recursive_mutex

mutex可以分为递归锁(recursive mutex)和非递归锁(non-recursive mutex)。可递归锁也可称为可重入锁(reentrant mutex)，非递归锁又叫不可重入锁(non-reentrant mutex)。

二者唯一的区别是，同一个线程可以多次获取同一个递归锁，不会产生死锁。而如果一个线程多次获取同一个非递归锁，则会产生死锁。

### 17.3.5 shared_mutex

这个锁就是我们平时所说的读写锁，线程可以将其设置为独占，在非独占的情况先多个线程可共享。所以有两种加锁方式，在C++17中实现。

## 17.4 *std::condition_variable*

条件变量用于阻塞当前线程直至有信号量通知，举个例子来说：

```cpp
std::mutex mutex;
std::condition_variable cv;
std::string data;
bool ready = false;
bool processed = false;
void Worker() {
    std::unique_lock<std::mutex> lock(mutex);
    cv.wait(lock, [] { return ready; });
    std::cout << "worker is processing data..." << std::endl;
    std::this_thread::sleep_for(std::chrono::seconds(1));
    data += " done";
    processed = true;
    std::cout << "worker notify main thread" << std::endl;
    lock.unlock();
    cv.notify_one();
}
int main() {
    std::thread worker(Worker);
    {
        std::lock_guard<std::mutex> lock(mutex);
        std::cout << "main thread is preparing for data..." << std::endl;
        std::this_thread::sleep_for(std::chrono::seconds(1));
        data = "sample data";
        ready = true;
        std::cout << "main thread get ready for data" << std::endl;
    }
    cv.notify_one();
    {
        std::unique_lock<std::mutex> lock(mutex);
        cv.wait(lock, [] { return processed; });
    }
    std::cout << "back to main thread, data:" << data << std::endl;
    worker.join();
    return 0;
}
```

程序一开始先启动worker线程并获得mutex锁，之后调用std::condition_variable::wait，由于当前ready为false则调用wait()释放mutex锁并阻塞当前线程等待被唤醒。与此同时主线程继续执行，使用lock_guard获得mutex锁，生成数据，将ready置成true，离开大括号作用域后lock_guard析构释放mutex锁并调用std::condition_variable::notify_one()通知wait的线程。此时主线程重新阻塞去竞争获得mutex锁。worker线程被唤醒后加锁，wait函数判断此时ready返回true不再调用wait阻塞当前线程，接着处理完数据之后将processed置true并对mutex进行解锁，最后通知主线程。此时主线程有可能被阻塞在竞争mutex的地方被唤醒并加锁，在wait函数判断processed为true后直接继续执行程序；有可能在wait被唤醒并加锁，重新判断processed返回true后继续运行，最终结束程序。

### 17.4.1 *Lost Wakeup and Spurious Wakeup*

* *Lost Wakeup*是指一个线程的*std::condition_variable::notify_one()*发生在了另外一个线程std::condition_variable::wait()之前，这样调用std::condition_variable::wait()的线程就不会被唤醒
* *Spurious Wakeup*是指一个调用std::condition_variable::wait()的线程被系统中断(EINTR)唤醒而不是被真正等待的线程唤醒，这是一种虚假的唤醒现象

为了防止这两种情况发生，根据CppCoreGuidelines CP.42: Don't `wait` without a condition，即调用wait函数时一定要加上一个Predicate函数，wait函数当Predicate返回false时才会真正调用wait函数，返回true时并不会去调用wait阻塞等待锁并加锁。

### 17.4.2 常用函数

```cpp
void notify_all() noexcept;//还有非成员函数void notify_all_at_thread_exit (condition_variable& cond, unique_lock<mutex> lck);
void notify_one() noexcept;//如果有多个线程都在等待，会随机唤醒一个线程
void wait (unique_lock<mutex>& lck);//该函数会阻塞当前线程直到被唤醒，被阻塞的同时当前线程会主动调用lck.unlock()释放其管理的锁，被唤醒之后主动加锁。
template <class Predicate>
void wait (unique_lock<mutex>& lck, Predicate pred);//该函数和上一个重载的区别在于当callable的pred返回false才会执行wait，返回true的时候不会去调用wait，此时若在之前没有进行加锁则就没有获得锁，该操作相当于while (!pred()) wait(lck);(which is specially useful to check against spurious wake-up calls)
template <class Clock, class Duration>
    cv_status wait_until (unique_lock<mutex>& lck,
                        const chrono::time_point<Clock,Duration>& abs_time);//当等待时间到了会返回cv_status::timeout，否则为cv_status::no_timeout
template <class Clock, class Duration, class Predicate>
       bool wait_until (unique_lock<mutex>& lck,
                        const chrono::time_point<Clock,Duration>& abs_time,
                        Predicate pred);
```

## 17.5 *std::atomic*

std::atomic<T>模板类，生成一个T类型的原子对象，并提供了一系列原子操作函数。其中T是trivially  copyable type满足：要么全部定义了拷贝/移动/赋值函数，要么全部没定义；没有虚成员；基类或其它任何非static成员都是trivally copyable。典型的内置类型bool、int等属于trivally copyable。再如class triviall{public: int x};也是。T能够被memcpy、memcmp函数使用，从而支持compare/exchange系列函数。有一条规则：不要在保护数据中通过用户自定义类型T通过参数指针或引用使得共享数据超出保护的作用域。atomic\<T\>编译器通常会使用一个内部锁保护，而如果用户自定义类型T通过参数指针或引用可能产生死锁。总之限制T可以更利于原子指令。注意某些原子操作可能会失败，比如atomic\<float\>、atomic\<double\>在compare_exchange_strong()时和expected相等但是内置的值表示形式不同于expected，还是返回false，没有原子算术操作针对浮点数;同理一些用户自定义的类型T由于内存的不同表示形式导致memcmp失败，从而使得一些相等的值仍返回false。

### 17.5.1 原子操作原理

C++11新引入的std::atomic主要是通过硬件的cmpxchgl(CAS,compare and swap)指令实现，linux内核将cmpxchgl封装成函数cmpxchg，实现如下：

```cpp
#define cmpxchg( ptr, _old, _new ) { \  
	volatile uint32_t *__ptr = (volatile uint32_t *)(ptr);   \  
	uint32_t __ret;                                     \  
	asm volatile( "lock; cmpxchgl %2,%1"           \  
	: "=a" (__ret), "+m" (*__ptr)                \  
	: "r" (_new), "0" (_old)                     \  
	: "memory");                 \  
	);                                             \  
	__ret;                                         \ 
}  
```

作用为将ptr的保存值和\_old进行比较，若相等则将\_new存入ptr，否则返回ptr保存的值。可以看到cmpxchgl指令前加了lock前缀，lock保证了指令不会受其他处理器或cpu核的影响。在PentiumPro之前，lock的实现，是通过锁住bus（总线），从而阻止其他cpu核的内存访问。可想而知，这种实现是非常低效的。从PentiumPro开始，lock只会阻塞其他cpu核对相关内存的缓存块的访问。

std::mutex的加锁过程其实也是有cmpxchg参与，只不过当发生竞争的时候会陷入内核进行等待，这时候性能会比较低，所以能用原子操作的尽量使用原子操作。

### 17.5.2 ABA问题

CAS在执行过程中有可能会因为ABA问题导致结果错误，我们通过atomic实现一个stack来介绍什么是ABA问题：

```cpp
template<typename _Ty>
struct LockFreeStackT
{
	struct Node
    {
		_Ty val;
		Node* next;
	};
	LockFreeStackT() : head_(nullptr) {}
	void push(const _Ty& val)
	{
		Node* node = new Node{ val, head_.load() };
		while (!head_.compare_exchange_strong(node->next, node));
        /*compare_exchange_strong函数用对象和第一个参数进行比较，如果相等则将对象的值替换为第二个参数并返回true，如果不相等，则将第一个参数的值赋为对象并返回false：
        if (head_ == node->next) {
        	head_ = node;
        	return true;
        } else {
        	node->next = head_;
        	return false;
        }
        */
	}
	void pop()
	{
		Node* node = head_.load();
		while (node && !head_.compare_exchange_strong(node, node->next);
		if (node) delete node;
	}
	std::atomic<Node*> head_;
};
```

整个逻辑很简单，如果新元素的next和栈顶一样，证明在你之前没人操作它，使用新元素替换栈顶退出即可；如果不一样，证明在你之前已经有人操作它，head\_在新建node之后被其他线程改动，而node->next仍然指向之前的head_，此时栈顶已发生改变，该函数会自动更新新元素的next值为改变后的栈顶；然后继续循环检测直到状态1成立退出。

假设现有两条线程，栈为A->B，此时线程1对栈进行pop操作，在CAS之前CPU切换去处理线程2。线程2此时连pop两次，将A和B都pop出来，又进行push操作，由于操作系统很可能会分配刚刚释放的内存，所以重新new的数据可能就是刚刚释放地址。此时CPU切到线程1，线程1进行CAS判断此时的head仍然是A，所以将A pop出来将B这个已经释放的内存设为栈顶。解决ABA问题的办法无非就是通过打标签的方式给每个节点进行打标签，而不是通过地址进行判断。

### 17.5.3 常用函数

```cpp
bool is_lock_free() const volatile;//判断atomic<T>中的T对象是否为lock free的，若是返回true。lock free(锁无关)指多个线程并发访问T不会出现data race，任何线程在任何时刻都可以不受限制的访问T
bool is_lock_free() const;
atomic() = default;//默认构造函数，T未初始化，可能后面被atomic_init(atomic<T>* obj,T val )函数初始化
constexpr atomic(T val);//T由val初始化
atomic(const atomic &) = delete;//禁止拷贝
atomic & operator=(const atomic &) = delete;//atomic对象间的相互赋值被禁止，但是可以显示转换再赋值，如atomic<int> a=static_cast<int>(b)这里假设atomic<int> b
atomic & operator=(const atomic &) volatile = delete;//atomic间不能赋值
T operator=(T val) volatile;//可以通过T类型对atomic赋值，如：atomic<int> a;a=10;
T operator=(T val);
operator T() const volatile;//读取被封装的T类型值，是个类型转换操作，默认内存序是memory_order_seq需要其它内存序则调用load
operator T() const;//如：atomic<int> a,a==0或者cout<<a<<endl都使用了类型转换函数
//以下函数可以指定内存序memory_order
T exchange(T val, memory_order = memory_order_seq_cst) volatile;//将T的值置为val，并返回原来T的值
T exchange(T val, memory_order = memory_order_seq_cst);
void store(T val, memory_order = memory_order_seq_cst) volatile;//将T值设为val
void store(T val, memory_order = memory_order_seq_cst);
T load(memory_order = memory_order_seq_cst) const volatile;//访问T值
T load(memory_order = memory_order_seq_cst) const;
bool compare_exchange_weak(T& expected, T val, memory_order = memory_order_seq_cst) volatile;//该函数直接比较原子对象所封装的值与参数expected的物理内容，所以某些情况下，对象的比较操作在使用 operator==()判断时相等，但compare_exchange_weak判断时却可能失败，因为对象底层的物理内容中可能存在位对齐或其他逻辑表示相同但是物理表示不同的值(比如true和2或3，它们在逻辑上都表示"真"，但在物理上两者的表示并不相同)。可以虚假的返回false(和expected相同)。若本atomic的T值和expected相同则用val值替换本atomic的T值，返回true;若不同则用本atomic的T值替换expected，返回false。
bool compare_exchange_weak(T &, T, memory_order = memory_order_seq_cst);
bool compare_exchange_strong(T &, T, memory_order = memory_order_seq_cst) volatile;//与compare_exchange_weak不同,strong版本的compare-and-exchange操作不允许返回 false，即原子对象所封装的值与参数expected的物理内容相同，比较操作一定会为true。不过在某些平台下，如果算法本身需要循环操作来做检查，compare_exchange_weak的性能会更好。因此对于某些不需要采用循环操作的算法而言,通常采用compare_exchange_strong更好
bool compare_exchange_strong(T &, T, memory_order = memory_order_seq_cst);
```

### 17.5.4 自旋锁实现

通过原子变量，我们可以自行实现标准库中没有的自旋锁：

```cpp
class spin_mutex {
    std::atomic<bool> flag = ATOMIC_VAR_INIT(false);
public:
    spin_mutex() = default;
    spin_mutex(const spin_mutex&) = delete;
    spin_mutex& operator= (const spin_mutex&) = delete;
    void lock() {
        bool expected = false;
        while (!flag.compare_exchange_strong(expected, true)) {
        	expected = false;
        }
    }
    void unlock() {
        flag.store(false);
    }
};
```

从网上的性能测试来看所有平台的自旋锁性能都无限接近无锁实现，并且使用方式和互斥锁几乎没有差别，但是仍然看场景，场景我们在17.3讨论过。

## 17.6 *std::async*

*std::async()*是一个接受回调(函数或函数对象)作为参数的函数模板，并有可能异步执行它们。*std::async*返回一个*std::future*，它存储由*std::async()*执行的函数对象返回的值。函数的参数可以作为函数指针参数后面的参数传递给*std::async()*。

std::async中的第一个参数是启动策略，它控制std::async的异步行为，我们可以用三种不同的启动策略来创建std::async：
std::launch::async：保证异步行为，即传递函数将在单独的线程中执行
std::launch::deferred：当其他线程的future调用get()或者wait()才执行该函数
std::launch::async | std::launch::deferred：默认行为。有了这个启动策略，它可以异步运行或不运行，这取决于系统的负载，但我们无法控制它。

## 17.7 *std::promise*

promise对象可以通过set_value保存某一类型 T 的值，该值可被 future 对象通过get阻塞读取（可能在另外一个线程中），因此 promise 也提供了一种线程同步的手段。在 promise 对象构造时可以和一个共享状态（通常是std::future，通过get_future）相关联，并可以在相关联的共享状态(std::future)上保存一个类型为 T 的值。

可以通过 get_future 来获取与该 promise 对象相关联的 future 对象，调用该函数之后，两个对象共享相同的共享状态(shared state)

- promise 对象是异步 Provider，它可以在某一时刻设置共享状态的值。
- future 对象可以异步返回共享状态的值，或者在必要的情况下阻塞调用者并等待共享状态标志变为 ready，然后才能获取共享状态的值。

举个例子来说明promise是如何使用的：

```cpp
#include <iostream>       // std::cout
#include <functional>     // std::ref
#include <thread>         // std::thread
#include <future>         // std::promise, std::future

void print_int(std::future<int>& fut) {
    int x = fut.get(); // 获取共享状态的值.
    std::cout << "value: " << x << '\n'; // 打印 value: 10.
}

int main ()
{
    std::promise<int> prom; // 生成一个 std::promise<int> 对象.
    std::future<int> fut = prom.get_future(); // 和 future 关联.
    std::thread t(print_int, std::ref(fut)); // 将 future 交给另外一个线程t.
    prom.set_value(10); // 设置共享状态的值, 此处和线程t保持同步.
    t.join();
    return 0;
}
```

future在主线程中和promise绑定，然后将future传给副线程，future在副线程中调用get阻塞等待共享变量ready。当主线程中的promise调用set_value后共享变量ready，副线程中的future唤醒线程并获得主线程set_value的值。

常用函数有：

```cpp
future<T> get_future();//返回一个和promise绑定的future对象
promise& operator= (promise&& rhs) noexcept;
promise& operator= (const promise&) = delete;//禁用复制，允许移动构造
void set_exception (exception_ptr p);//设置异常，当future调用get的时候抛出异常
void set_exception_at_thread_exit (exception_ptr p);//线程结束时设置future同步的值
void set_value (const T& val);
void set_value (T&& val);
void promise<R&>::set_value (R& val);   // when T is a reference type (R&)
void promise<void>::set_value (void);   // when T is void
void set_value_at_thread_exit (const T& val);
void set_value_at_thread_exit (T&& val);
void promise<R&>::set_value_at_thread_exit (R& val);// when T is a reference type (R&)
void promise<void>::set_value_at_thread_exit (void);// when T is void
```

## 17.8 *std::future*

std::future 可以用来获取异步任务的结果，因此可以把它当成一种简单的线程间同步的手段。std::future 通常由某个Provider创建，你可以把Provider想象成一个异步任务的提供者，Provider 在某个线程中设置共享状态的值，与该shared state相关联的std::future对象调用get（通常在另外一个线程中）获取该值，如果共享状态的标志不为 ready，则调用 std::future::get 会阻塞当前的调用者，直到 Provider 设置了共享状态的值（此时共享状态的标志变为 ready），std::future::get 返回异步任务的值或异常（如果发生了异常）。

一个有效(valid)的std::future对象通常由以下三种Provider创建，并和某个共享状态相关联。Provider可以是函数或者类，其实我们前面都已经提到了，他们分别是：

- std::async函数返回一个future。
- std::promise::get_future，get_future为 promise类的成员函数。
- std::packaged_task::get_future，此时get_future为packaged_task的成员函数。

std::shared_future与std::future类似，但是std::shared_future可以拷贝、多个std::shared_future可以共享某个共享状态的最终结果(即共享状态的某个值或者异常)，这样就可以实现多个线程等待一个线程结果的场景。shared_future可以通过某个std::future对象隐式转换（参见std::shared_future的构造函数），或者通过std::future::share()显示转换，无论哪种转换，被转换的那个 std::future对象都会变为not-valid。一个有效的std::future对象只能通过std::async()，std::future::get_future或者std::packaged_task::get_future来初始化，可通过valid()函数来判断一个future对象是否valid。具体例子可以看17.7。

常用函数有：

```cpp
T get();//Returns the value stored in the shared state (or throws its exception) when the shared state is ready.
future& operator= (future&& rhs) noexcept;
future& operator= (const future&) = delete;
shared_future<T> share();//Returns a shared_future object that acquires the shared state of the future object.执行后原来的future变成valid
bool valid() const noexcept;//默认构造函数的future和调用过get的future都返回false，除非被其他valid的future进行移动赋值
void wait() const;//等待直到shared state变成ready
template <class Rep, class Period>
future_status wait_for (const chrono::duration<Rep,Period>& rel_time) const;//等待shared state变成ready或者时间到。若时间到了shared state还未ready则返回future_status::timeout；若ready返回future_status::ready；若future对象由async构造函数返回，并且async包含的是一个std::launch::deferred同步执行函数，则返回future_status::deferred
template <class Clock, class Duration>
future_status wait_until (const chrono::time_point<Clock,Duration>& abs_time) const;//等待直到一个特定时间点，若等待时间点在当前之前则返回future_status::timeout
```

## 17.9 线程池

通过上述介绍的C++11的并发编程库我们可以实现一个简单的线程池，只需要用到mutex和condition_variable：

```cpp
#include <iostream>
#include <mutex>
#include <condition_variable>
#include <functional>
#include <queue>
#include <thread>

class ThreadPool {
public:
    explicit ThreadPool(size_t threadCount)
        : data_(std::make_shared<data>()) {
        for (size_t i = 0; i < threadCount; ++i) {
            std::thread([data = data_] {
                std::unique_lock<std::mutex> lk(data->mtx);
                for (;;) {
                    if (!data->tasks.empty()) {
                        auto current = std::move(data->tasks.front());
                        data->tasks.pop();
                        lk.unlock();
                        current();
                        lk.lock();
                    }
                    else if (data->isShutdown) {
                        break;
                    }
                    else {
                        data->cond.wait(lk);
                    }
                }
                }).detach();
        }
    }

    ThreadPool() = default;
    ThreadPool(ThreadPool&&) = default;

    ~ThreadPool() {
        if ((bool)data_) {
            {
                std::lock_guard<std::mutex> lk(data_->mtx);
                data_->isShutdown = true;
            }
            data_->cond.notify_all();
        }
    }

    template <class F>
    void execute(F&& task) {
        {
            std::lock_guard<std::mutex> lk(data_->mtx);
            data_->tasks.emplace(std::forward<F>(task));
        }
        data_->cond.notify_one();
    }

private:
    struct data {
        std::mutex mtx;
        std::condition_variable cond;
        bool isShutdown = false;
        std::queue<std::function<void()>> tasks;
    };
    std::shared_ptr<data> data_;
};
int main()
{
    ThreadPool tp(10);
    tp.execute([]() {
        for (int i = 0; i < 20; ++i) {
            std::cout << "i:" << i << std::endl;
        }
    });
    tp.execute([]() {
        for (int i = 0; i < 20; ++i) {
            std::cout << "i:" << i << std::endl;
        }
    });
    system("pause");
}
```

在ThreadPool类的构造函数中我们会起threadCount个线程并进入一个死循环中，每一个线程都通过条件变量等待被唤醒。当ThreadPool的对象调用execute接口并传入函数指针之后将函数指针push进任务队列中，接着唤醒一个线程。被随机唤醒的线程从任务队列中pop出一个函数任务开始调用。

这个线程池可能还比较简单，只能执行无参数无返回的任务，在实际生产中可能难以适用，但是通过简单的修改我们可以通过多态加闭包的方法实现不同函数的调用。